{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect and compare LLMs\n",
    "\n",
    "- Connect to the grok API and choose a model\n",
    "- Connect to the Gemini API and choose a model\n",
    "- Connect to the OpenAI API and choose 4o-mini\n",
    "\n",
    "### Create a prompt and inject a little text snippet of your liking\n",
    "- The LLM should use the injected information to answer a question.\n",
    "\n",
    "### Compare the outputs\n",
    "- Use the same method for every model.\n",
    "- Do you see differences?\n",
    "\n",
    "**Tipp:** for prompt injection you can either use string concatenation or the python String formatter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the API key using the variable name defined in the .env file\n",
    "genai_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/quickstart?hl=de&lang=python\n",
    "examples: https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb?hl=de#scrollTo=WxiIfsbA0WdH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klar, hier ist ein Witz über Holzfäller:\n",
      "\n",
      "Warum war der Holzfäller so gut im Führen von Geheimnissen?\n",
      "\n",
      "Weil er sie immer gut \"versparrt\" hat!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = genai_client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"Erzähle mir einen Witz über Holzfäller.\"]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Klar, hier ist einer für dich:\\n\\nWarum hatte der Programmierer kalte Füße? \\nWeil er immer mit offenen Fenstern programmiert hat!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI-Client initialisieren und Chat anfragen\n",
    "client = OpenAI(api_key=openai_api_key)     # API-Key aus .env  \n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",                  # oder \"gpt-4o-mini\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher Assistent.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Erzähle mir einen Witz über Programmierer.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq\n",
    "https://console.groq.com/docs/quickstart\n",
    "\n",
    "goal: llama-3.3-70b-versatile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warum ging der Hund zum Friseur?\n",
      "\n",
      "Weil er seine Haare schneiden lassen wollte, aber letztendlich bekam er nur einen \"Kurz\"-Schnitt!\n",
      "\n",
      "Ich hoffe, das hat dich zum Lachen gebracht! Hunde sind einfach zu süß, um nicht darüber zu lachen. Wenn du noch mehr hören möchtest, habe ich noch einen paar Witzchen auf Lager!\n"
     ]
    }
   ],
   "source": [
    "# Groq-Client initialisieren und Chat anfragen\n",
    "client = Groq(api_key=groq_api_key)         # API-Key aus .env  \n",
    "llm = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher Assistent.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Erzähle mir einen Witz über Hunde.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
